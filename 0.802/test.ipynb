{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.initializers import RandomNormal,glorot_uniform\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的核心思路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础特征\n",
    "all_col=['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id',\n",
    "       'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags',\n",
    "       'app_first_class', 'app_second_class', 'age', 'city', 'city_rank',\n",
    "       'device_name', 'device_size', 'career', 'gender', 'net_type',\n",
    "       'residence', 'his_app_size', 'his_on_shelf_time', 'app_score',\n",
    "       'emui_dev', 'list_time', 'device_price', 'up_life_duration',\n",
    "       'up_membership_grade', 'membership_life_duration', 'consume_purchase',\n",
    "        'communication_avgonline_30d', 'indu_name']\n",
    "# 时间序列特征\n",
    "# his_adv_prim_id：his_adv_id\n",
    "# shape=(m,20)其中m表示用户数量，20表示序列长度，不足20的用0填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以字典的形式定义每个类别的embedding_dim，vocabulary_size\n",
    "# 具体的计算代码如下;\n",
    "# all_data = pd.concat([train_data, test_data]).reset_index(drop=True)\n",
    "# params = {'feature_config':{}}\n",
    "# for i in tqdm(all_col):\n",
    "#     params['feature_config'][i] = {}\n",
    "#     params['feature_config'][i]['vocabulary_size'] = all_data[i].max()+1\n",
    "#     params['feature_config'][i]['embedding_dim'] = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了减小计算时间，可以将结果直接以字典的形式给出，\n",
    "params={'feature_config': {\n",
    "  'task_id': {'vocabulary_size': 4932, 'embedding_dim': 16},'adv_id': {'vocabulary_size': 5956, 'embedding_dim': 16},\n",
    "  'creat_type_cd': {'vocabulary_size': 8, 'embedding_dim': 16},'adv_prim_id': {'vocabulary_size': 114, 'embedding_dim': 16},\n",
    "  'dev_id': {'vocabulary_size': 61, 'embedding_dim': 16},'inter_type_cd': {'vocabulary_size': 4, 'embedding_dim': 16},\n",
    "  'slot_id': {'vocabulary_size': 12, 'embedding_dim': 16},'spread_app_id': {'vocabulary_size': 79, 'embedding_dim': 16},\n",
    "  'tags': {'vocabulary_size': 32, 'embedding_dim': 16},'app_first_class': {'vocabulary_size': 3, 'embedding_dim': 16},\n",
    "  'app_second_class': {'vocabulary_size': 19, 'embedding_dim': 16},'age': {'vocabulary_size': 8, 'embedding_dim': 16},\n",
    "  'city': {'vocabulary_size': 344, 'embedding_dim': 16},'city_rank': {'vocabulary_size': 4, 'embedding_dim': 16},\n",
    "  'device_name': {'vocabulary_size': 94, 'embedding_dim': 16},'device_size': {'vocabulary_size': 231, 'embedding_dim': 16},\n",
    "  'career': {'vocabulary_size': 9, 'embedding_dim': 16},'gender': {'vocabulary_size': 3, 'embedding_dim': 16},\n",
    "  'net_type': {'vocabulary_size': 5, 'embedding_dim': 16},'residence': {'vocabulary_size': 36, 'embedding_dim': 16},\n",
    "  'his_app_size': {'vocabulary_size': 21, 'embedding_dim': 16},'his_on_shelf_time': {'vocabulary_size': 4, 'embedding_dim': 16},\n",
    "  'app_score': {'vocabulary_size': 2, 'embedding_dim': 16},'emui_dev': {'vocabulary_size': 18, 'embedding_dim': 16},\n",
    "  'list_time': {'vocabulary_size': 19, 'embedding_dim': 16},'device_price': {'vocabulary_size': 8, 'embedding_dim': 16},\n",
    "  'up_life_duration': {'vocabulary_size': 21, 'embedding_dim': 16},'up_membership_grade': {'vocabulary_size': 4, 'embedding_dim': 16},\n",
    "  'membership_life_duration': {'vocabulary_size': 21, 'embedding_dim': 16},'consume_purchase': {'vocabulary_size': 9, 'embedding_dim': 16},\n",
    "  'communication_avgonline_30d': {'vocabulary_size': 14, 'embedding_dim': 16},'indu_name': {'vocabulary_size': 42, 'embedding_dim': 16}\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入特征构造\n",
    "# （1）根据字典params构造特征的输入，以及对特征进行嵌入\n",
    "features = params['feature_config']\n",
    "input_dict = {}\n",
    "embedding_dict = {}\n",
    "embedding_lookup = {}\n",
    "for fea in features:\n",
    "    # 构造input\n",
    "    fea_input = Input(shape=(1,),name = fea)\n",
    "    input_dict[fea] = fea_input\n",
    "    \n",
    "    # 构造enbeddingg\n",
    "    feature_embedding = Embedding(\n",
    "        features[fea]['vocabulary_size'],features[fea]['embedding_dim'],\n",
    "        embeddings_initializer=RandomNormal(mean=0.0, stddev=0.0001, seed=1996),\n",
    "        name=\"emb_\" + fea)\n",
    "    embedding_dict[fea] = feature_embedding\n",
    "\n",
    "    # 构造embedding_lookup，将Input输入Embedding(m,n,name)(Input)实现lookup过程\n",
    "    embedding = feature_embedding(fea_input)\n",
    "    embedding_lookup[fea] = embedding\n",
    "\n",
    "# 时间序列特征构造输入\n",
    "input_dict['his_adv_id'] = Input(shape=(20,),name = 'his_adv_id')\n",
    "input_dict['his_adv_prim_id'] = Input(shape=(20,),name = 'his_adv_prim_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义FM模型\n",
    "class FM(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        super(FM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        super(FM, self).build(input_shape) \n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \n",
    "        ad_group = tf.reduce_sum(inputs[0], axis=1)\n",
    "        user_group = tf.reduce_sum(inputs[1], axis=1)\n",
    "        cross_term = tf.reduce_sum(ad_group*user_group,axis=1,keepdims=True)\n",
    "#         cross_term = tf.keras.backend.sum(ad_group*user_group,axis=1)\n",
    "        return cross_term\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)\n",
    "class Add(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Add, self).__init__(**kwargs)\n",
    "    def call(self, input, **kwargs):\n",
    "        return input[0]+input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method FM.call of <__main__.FM object at 0x000002152A814348>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method FM.call of <__main__.FM object at 0x000002152A814348>>, which Python reported as:\n",
      "    def call(self, inputs, **kwargs):\n",
      "        \n",
      "        ad_group = tf.reduce_sum(inputs[0], axis=1)\n",
      "        user_group = tf.reduce_sum(inputs[1], axis=1)\n",
      "        cross_term = tf.reduce_sum(ad_group*user_group,axis=1,keepdims=True)\n",
      "#         cross_term = tf.keras.backend.sum(ad_group*user_group,axis=1)\n",
      "        return cross_term\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method FM.call of <__main__.FM object at 0x000002152A814348>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method FM.call of <__main__.FM object at 0x000002152A814348>>, which Python reported as:\n",
      "    def call(self, inputs, **kwargs):\n",
      "        \n",
      "        ad_group = tf.reduce_sum(inputs[0], axis=1)\n",
      "        user_group = tf.reduce_sum(inputs[1], axis=1)\n",
      "        cross_term = tf.reduce_sum(ad_group*user_group,axis=1,keepdims=True)\n",
      "#         cross_term = tf.keras.backend.sum(ad_group*user_group,axis=1)\n",
      "        return cross_term\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    }
   ],
   "source": [
    "# 模型的第一部分\n",
    "# 对广告特征和用户特征的embedding_lookup结果进行交叉：FM模型\n",
    "ad_group = concatenate([embedding_lookup[i] for i in ['adv_id','task_id','creat_type_cd','adv_prim_id','dev_id',\n",
    "                            'inter_type_cd','spread_app_id','tags','app_first_class','app_second_class','his_app_size','his_on_shelf_time',\n",
    "                                                             'app_score','indu_name']],axis = 1)\n",
    "        \n",
    "user_group = concatenate([embedding_lookup[i] for i in ['age','city','city_rank','device_name','device_size',\n",
    "                            'career','gender','net_type','residence','emui_dev','list_time','device_price','up_life_duration','up_membership_grade',\n",
    "                                        'membership_life_duration','consume_purchase','communication_avgonline_30d']],axis = 1)\n",
    "\n",
    "FMout = FM(name = 'FM')([ad_group,user_group])\n",
    "\n",
    "# 接入全连接层,得到FM模型的输出\n",
    "FMout = Dense(1)(FMout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的第二部分\n",
    "# 对于时间序列数据采用双向GRU进行建模\n",
    "his_adv_id = embedding_dict['adv_id'](input_dict['his_adv_id'])\n",
    "his_adv_id = Bidirectional(GRU(128))(his_adv_id)\n",
    "his_adv_prim_id = embedding_dict['adv_prim_id'](input_dict['his_adv_prim_id'])\n",
    "his_adv_prim_id = Bidirectional(GRU(128))(his_adv_prim_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有的基础特征的嵌入结果进行concatenate,然后Flatten\n",
    "embedding_concat = Flatten()(concatenate([embedding_lookup[i] for i in embedding_lookup]))\n",
    "# 时间序列与基础特征的结果合并\n",
    "embedding_concat=concatenate([embedding_concat,his_adv_id,his_adv_prim_id,])#user_app_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入一系列全连接层\n",
    "dense = Dropout(0.3)(embedding_concat)\n",
    "dense = Dense(1024)(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = Activation(activation=\"relu\")(dense)\n",
    "dense = Dropout(0.3)(dense)\n",
    "dense = Dense(512)(dense)\n",
    "dense = BatchNormalization()(dense)\n",
    "dense = Activation(activation=\"relu\")(dense)\n",
    "dense = Dense(1)(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合FM\n",
    "output = Add()([dense,FMout])#exFM_logit\n",
    "output = Add()([dense,FMout])#exFM_logit\n",
    "output = Activation(activation=\"sigmoid\")(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型初始化与编译\n",
    "model = Model(inputs=[input_dict[i] for i in input_dict], outputs=output)\n",
    "# model = multi_gpu_model(model, gpus=4)\n",
    "model.compile(optimizer ='adam',\n",
    "              loss= 'binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ffm_model2.h5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"ffm_model%d.h5\" % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data['label']\n",
    "mode = 1\n",
    "stack_test = np.zeros((len(test_data),1))\n",
    "stack_train = np.zeros((train_data.shape[0], 1))\n",
    "if mode == 1:\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=1996, shuffle=True)\n",
    "    for index, (train_index, test_index) in enumerate(skf.split(train_data, target)):\n",
    "        K.clear_session()\n",
    "        # 定义回调\n",
    "        # 模型保存路径\n",
    "        filepath = \"ffm_model%d.h5\" % index\n",
    "        \n",
    "        # 保存模型,保存每一个epoch最好的模型。\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        # 当 val_loss 在patience次数内不在减小时。减小学习率，其中：new_lr = lr * factor，\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=1, min_lr=0.0001, verbose=1)\n",
    "        # 提早停止\n",
    "        earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2,verbose=1, mode='auto')\n",
    "        callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "    \n",
    "        # 构造验证集和训练集\n",
    "        trian_x = make_data(train_index)\n",
    "        valid_x = make_data(test_index)\n",
    "        trian_y = np.array(target[train_index])\n",
    "        valid_y = np.array(target[test_index])\n",
    "        \n",
    "        # 模型的训练\n",
    "        model.fit(trian_x,trian_y, batch_size=4096, epochs=10, verbose=1, \n",
    "                  validation_data=(valid_x, valid_y),callbacks=callbacks)\n",
    "\n",
    "        nn_model.model.load_weights(filepath)\n",
    "        stack_test += nn_model.predict(make_test())\n",
    "        stack_train[test_index] = nn_model.predict(valid_x)\n",
    "        \n",
    "        if index==0:\n",
    "            \n",
    "            reslgb = pd.read_csv('lgbres.csv')\n",
    "            reslgb['probability']=stack_test[1000000:]\n",
    "            reslgb[['id','probability']].to_csv('subnn.csv',index=False)\n",
    "else:\n",
    "    trian_x = make_train()\n",
    "    valid_x = make_valid()\n",
    "    trian_y = np.array(target[0:35897957])\n",
    "    valid_y = np.array(target[35897957:])\n",
    "    model.train(trian_x,valid_x,trian_y,valid_y,4096,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
